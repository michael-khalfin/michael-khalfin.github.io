{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9d4f384",
   "metadata": {},
   "source": [
    "# The K-Secretary Problem and Optimal Thresholds\n",
    "\n",
    "The problem setup, definitions, LP formulation, and its interpretation are from Buchbinder Jain Singh '14 and Chan Chen Jiang '15.\n",
    "\n",
    "## Problem Setup\n",
    "\n",
    "**Input:**\n",
    "- $n$ items arrive in uniformly random order\n",
    "- Items have a total ordering (only relative comparisons observable)\n",
    "- Algorithm has $K$ quotas for selecting items\n",
    "- Decisions are **irrevocable** (made upon arrival)\n",
    "\n",
    "**Goal:** Maximize $\\mathbb{E}[\\text{number of selected items among the } K \\text{ best overall}]$\n",
    "\n",
    "**Performance ratio:** $\\frac{\\mathbb{E}[\\text{number selected among } K \\text{ best}]}{K}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb0a683",
   "metadata": {},
   "source": [
    "## Key Definitions\n",
    "\n",
    "**k-potential:** An item arriving at step $i$ is a **k-potential** if it ranks k-th among all items arrived so far (including itself).\n",
    "\n",
    "**k≥-potential:** An item is a **k≥-potential** if it is a $k'$-potential for some $k' \\leq k$.\n",
    "\n",
    "**Quotas:** $Q_K, Q_{K-1}, \\ldots, Q_1$ (used in order: $Q_K$ first, $Q_1$ last)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f273fcc0",
   "metadata": {},
   "source": [
    "## Optimal K-Threshold Algorithm\n",
    "\n",
    "**Parameters:** $K^2$ thresholds $\\{\\tau_{j,k} : j \\in [K], k \\in [K]\\}$ satisfying:\n",
    "1. For each quota $j$: $0 < \\tau_{j,1} \\leq \\tau_{j,2} \\leq \\cdots \\leq \\tau_{j,K} \\leq 1$\n",
    "2. For each potential level $k$: $0 < \\tau_{K,k} \\leq \\tau_{K-1,k} \\leq \\cdots \\leq \\tau_{1,k} \\leq 1$\n",
    "\n",
    "**Selection rule:** \n",
    "- After time $\\tau_{j,k}$, quota $Q_j$ may be used for any $k$≥-potential\n",
    "- Select greedily: whenever an item can be selected, use the highest-indexed available quota\n",
    "\n",
    "**Intuition:** Each quota \"matures\" progressively (condition 1), and higher-indexed quotas mature earlier (condition 2)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0949d9",
   "metadata": {},
   "source": [
    "## Linear Programming Formulation: $\\text{LP}_n(K,K)$\n",
    "\n",
    "### Decision Variables\n",
    "\n",
    "$$z_{j|k}(i) = \\Pr[\\text{item at step } i \\text{ selected using quota } Q_j \\mid \\text{it is a } k\\text{-potential}]$$\n",
    "\n",
    "### The Linear Program\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\max \\quad & \\sum_{j=1}^K \\sum_{k=1}^K \\sum_{i=1}^n \\frac{1}{n} \\sum_{\\ell=k}^K \\delta_{k|\\ell}(i) \\cdot z_{j|k}(i) \\\\\n",
    "\\text{s.t.} \\quad & z_{j|k}(i) \\leq \\sum_{m=1}^{i-1} \\frac{1}{m} \\sum_{\\ell=1}^K \\left[z_{(j+1)|\\ell}(m) - z_{j|\\ell}(m)\\right], \n",
    "\\quad \\forall i \\in [n], k \\in [K], 1 \\leq j < K \\\\\n",
    "& z_{K|k}(i) \\leq 1 - \\sum_{m=1}^{i-1} \\frac{1}{m} \\sum_{\\ell=1}^K z_{K|\\ell}(m), \n",
    "\\quad \\forall i \\in [n], k \\in [K] \\\\\n",
    "& z_{j|k}(i) \\geq 0, \\quad \\forall i \\in [n], j, k \\in [K] \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\\delta_{k|\\ell}(i) = \\frac{\\binom{n-i}{\\ell-k}\\binom{i-1}{k-1}}{\\binom{n-1}{\\ell-1}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9146207",
   "metadata": {},
   "source": [
    "## Interpretation\n",
    "\n",
    "### The $\\delta$ Coefficients\n",
    "\n",
    "$$\\delta_{k|\\ell}(i) = \\Pr[\\text{item at step } i \\text{ is a } k\\text{-potential} \\mid \\text{it is the } \\ell\\text{-th best overall}]$$\n",
    "\n",
    "**Explanation:** Given the $\\ell$-th best item arrives at step $i$, it is a $k$-potential iff exactly $(k-1)$ of the $(\\ell-1)$ better items arrive in the $(i-1)$ steps before it.\n",
    "\n",
    "### Objective Function\n",
    "\n",
    "Define auxiliary quantities:\n",
    "- $\\gamma_k(i) := \\sum_{j=1}^K z_{j|k}(i) = \\Pr[\\text{item at step } i \\text{ selected} \\mid \\text{it is a } k\\text{-potential}]$\n",
    "- $\\beta_\\ell(i) := \\sum_{k=1}^\\ell \\delta_{k|\\ell}(i) \\cdot \\gamma_k(i) = \\Pr[\\ell\\text{-th best item selected} \\mid \\text{it arrives at step } i]$\n",
    "\n",
    "The objective equals:\n",
    "$$\\sum_{\\ell=1}^K \\underbrace{\\sum_{i=1}^n \\frac{1}{n} \\beta_\\ell(i)}_{\\Pr[\\ell\\text{-th best selected}]}$$\n",
    "\n",
    "**Interpretation:** Sum over all $K$ best items of the probability each is selected (since each arrives at step $i$ with probability $1/n$).\n",
    "\n",
    "### Constraints\n",
    "\n",
    "$$\\sum_{m=1}^{i-1} \\frac{1}{m} \\sum_{\\ell=1}^K z_{j|\\ell}(m) = \\Pr[\\text{quota } Q_j \\text{ used by step } i]$$\n",
    "\n",
    "**Explanation:** At each step $m < i$, an $\\ell$-potential arrives with probability $1/m$, and quota $Q_j$ is used with probability $z_{j|\\ell}(m)$.\n",
    "\n",
    "The RHS of constraints gives:\n",
    "- $\\sum_{m=1}^{i-1} \\frac{1}{m} \\sum_{\\ell=1}^K [z_{(j+1)|\\ell}(m) - z_{j|\\ell}(m)] = \\Pr[\\text{exactly } j \\text{ quotas remain at step } i]$ for $j < K$\n",
    "- $1 - \\sum_{m=1}^{i-1} \\frac{1}{m} \\sum_{\\ell=1}^K z_{K|\\ell}(m) = \\Pr[\\text{all } K \\text{ quotas remain at step } i]$ for $j = K$\n",
    "\n",
    "**Constraint meaning:** To select with quota $Q_j$ at step $i$, that quota must be available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c37370",
   "metadata": {},
   "source": [
    "**Theorem:** Any K-secretary algorithm induces feasible $z$ values with objective value equal to $\\mathbb{E}[\\text{number selected among } K \\text{ best}]$.\n",
    "\n",
    "**Corollary:** The optimal LP value equals the optimal performance ratio achievable by any algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ffb8be",
   "metadata": {},
   "source": [
    "# Demo: A Framework for Analyzing the Class of Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cb9b629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import comb\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import pyomo.environ as pyo\n",
    "from pyomo.opt import SolverFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0be59cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_delta(n, i, k, ell):\n",
    "    \"\"\"\n",
    "    Compute delta_{k|ell}(i) = P[item at step i is k-potential | it's ell-th best overall]\n",
    "    \"\"\"\n",
    "    if i < 1 or k < 1 or ell < k or k > i:\n",
    "        return 0.0\n",
    "    \n",
    "    numerator = comb(n - i, ell - k, exact=True) * comb(i - 1, k - 1, exact=True)\n",
    "    denominator = comb(n - 1, ell - 1, exact=True)\n",
    "    \n",
    "    return numerator / denominator if denominator > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1166d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_k_secretary_lp_model(n, K, verbose=False):\n",
    "    \"\"\"\n",
    "    Creates a Pyomo ConcreteModel for the base K-secretary LP.\n",
    "    Does not solve.\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(f\"Building Pyomo model components for n={n}, K={K}...\")\n",
    "\n",
    "    # Precompute delta\n",
    "    delta = np.zeros((n, K, K))\n",
    "    for i in range(1, n + 1):\n",
    "        for k in range(1, K + 1):\n",
    "            for ell in range(k, K + 1):\n",
    "                delta[i-1, k-1, ell-1] = compute_delta(n, i, k, ell)\n",
    "    \n",
    "    model = pyo.ConcreteModel()\n",
    "\n",
    "    # --- Indices ---\n",
    "    model.J = pyo.Set(initialize=range(K)) # Quotas\n",
    "    model.K = pyo.Set(initialize=range(K)) # Potentials\n",
    "    model.I = pyo.Set(initialize=range(n)) # Steps\n",
    "    model.VARS = model.J * model.K * model.I\n",
    "\n",
    "    # --- Variables ---\n",
    "    # z[j, k, i] (using 0-based indexing)\n",
    "    model.z = pyo.Var(model.VARS, bounds=(0.0, 1.0))\n",
    "\n",
    "    # --- Objective Function ---\n",
    "    c_dict = {}\n",
    "    for j, k, i in model.VARS:\n",
    "        c_val = 0.0\n",
    "        for ell in range(k, K): # ell is 0-indexed k..K-1\n",
    "            c_val += (1.0 / n) * delta[i, k, ell]\n",
    "        c_dict[(j,k,i)] = c_val\n",
    "    \n",
    "    model.objective = pyo.Objective(\n",
    "        expr=sum(c_dict[v] * model.z[v] for v in model.VARS),\n",
    "        sense=pyo.maximize\n",
    "    )\n",
    "\n",
    "    # --- Constraints ---\n",
    "    model.lp_constrs = pyo.ConstraintList()\n",
    "\n",
    "    # Constraints for j < K (j_idx = 0...K-2)\n",
    "    for j in range(K - 1):\n",
    "        for k in range(K):\n",
    "            for i in range(1, n): # i_idx = 1...n-1\n",
    "                rhs = 0\n",
    "                for m in range(i): # m_idx = 0...i-1\n",
    "                    for ell in range(K):\n",
    "                        rhs += (1.0 / (m + 1)) * (model.z[j+1, ell, m] - model.z[j, ell, m])\n",
    "                model.lp_constrs.add(model.z[j, k, i] <= rhs)\n",
    "    \n",
    "    # Constraints for j = K (j_idx = K-1)\n",
    "    j = K - 1\n",
    "    for k in range(K):\n",
    "        for i in range(1, n): # i_idx = 1...n-1\n",
    "            rhs = 1.0\n",
    "            for m in range(i): # m_idx = 0...i-1\n",
    "                for ell in range(K):\n",
    "                    rhs -= (1.0 / (m + 1)) * model.z[j, ell, m]\n",
    "            model.lp_constrs.add(model.z[j, k, i] <= rhs)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Base model components built.\")\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae4e3ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_base_lp_pyomo(n, K, verbose=True):\n",
    "    \"\"\"\n",
    "    Solves the base K-secretary LP (B=0) using Pyomo.\n",
    "    \"\"\"\n",
    "    # Create the base model\n",
    "    model = create_k_secretary_lp_model(n, K, verbose=verbose)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Base model created. Solving with Gurobi...\")\n",
    "\n",
    "    # Solve\n",
    "    opt = SolverFactory('gurobi')\n",
    "    results = opt.solve(model, tee=False) # tee=True to see solver logs\n",
    "    \n",
    "    obj_val = 0.0\n",
    "    if results.solver.termination_condition == pyo.TerminationCondition.optimal:\n",
    "        obj_val = pyo.value(model.objective)\n",
    "        if verbose:\n",
    "            print(f\"\\n{'='*60}\\nOPTIMAL SOLUTION FOUND (B=0)\\n{'='*60}\")\n",
    "            print(f\"Expected # of top-{K} items selected: {obj_val:.6f}\")\n",
    "            print(f\"Competitive ratio: {obj_val / K:.6f}\")\n",
    "            print(f\"{'='*60}\\n\")\n",
    "    else:\n",
    "        print(f\"Base LP solve failed: {results.solver.termination_condition}\")\n",
    "        return None, None\n",
    "\n",
    "    return model, obj_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd04efe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving K-secretary problem with n=100, K=2 (Pyomo B=0)\n",
      "This is the exact LP from equations (1)-(4)\n",
      "\n",
      "Building Pyomo model components for n=100, K=2...\n",
      "Base model components built.\n",
      "Base model created. Solving with Gurobi...\n",
      "\n",
      "============================================================\n",
      "OPTIMAL SOLUTION FOUND (B=0)\n",
      "============================================================\n",
      "Expected # of top-2 items selected: 0.987887\n",
      "Competitive ratio: 0.493943\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run for n=500, K=2 with Pyomo\n",
    "n_demo = 100\n",
    "K_demo = 2\n",
    "\n",
    "print(f\"Solving K-secretary problem with n={n_demo}, K={K_demo} (Pyomo B=0)\")\n",
    "print(f\"This is the exact LP from equations (1)-(4)\\n\")\n",
    "\n",
    "# We get the solved model and the base objective value\n",
    "base_model, obj_val_base = solve_base_lp_pyomo(n_demo, K_demo, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f250ed9c",
   "metadata": {},
   "source": [
    "The LP solution finds a single, fully optimal algorithm. We can, however, analyze the *class* of ordinal algorithms by parameterizing them.\n",
    "\n",
    "We can formalize this by introducing an external agent (\"nature\") that has a \"budget\" $B$. This budget allows the agent to choose $B$ of the algorithm's decision variables and fix them to specific values. This defines a subclass of algorithms, allowing us to analyze the performance spectrum.\n",
    "\n",
    "### 1. Define the \"Reward\" Objective\n",
    "\n",
    "We use the original K-secretary LP objective (a maximization problem) directly.\n",
    "\n",
    "Let $I$ be the set of all variable indices $v = (j, k, i)$.\n",
    "Let $z = \\{z_v\\}_{v \\in I}$ be the vector of all decision variables $z_{j|k}(i)$.\n",
    "Let $c_v$ be the objective coefficient for variable $z_v$.\n",
    "\n",
    "The \"reward\" is the original LP objective:\n",
    "$$\\text{Obj}(z) = \\sum_{v \\in I} c_v z_v$$\n",
    "\n",
    "Let $\\text{LP-Constraints}(z)$ represent the full set of original LP constraints.\n",
    "\n",
    "### 2. Define the Performance Function $Q(y, \\zeta)$\n",
    "\n",
    "We introduce two vectors chosen by \"nature\":\n",
    "1.  A binary vector $y = \\{y_v\\}_{v \\in I}$, where $y_v=1$ if variable $v$ is fixed, and $y_v=0$ if it is free.\n",
    "2.  A real-valued vector $\\zeta = \\{\\zeta_v\\}_{v \\in I}$, which specifies the values nature assigns to the fixed variables.\n",
    "\n",
    "The function $Q(y, \\zeta)$ quantifies the *algorithm's best possible performance* (maximum reward) given nature's choices $y$ and $\\zeta$:\n",
    "\n",
    "$$Q(y, \\zeta) = \\max_{z} \\quad \\text{Obj}(z)$$\n",
    "$$\\text{s.t.} \\quad \\text{LP-Constraints}(z)$$\n",
    "$$y_v (z_v - \\zeta_v) = 0, \\quad \\forall v \\in I$$\n",
    "\n",
    "The constraint $y_v (z_v - \\zeta_v) = 0$ enforces the logic:\n",
    "-   If $y_v = 1$ (variable is fixed), then $z_v - \\zeta_v = 0$, so $z_v = \\zeta_v$.\n",
    "-   If $y_v = 0$ (variable is free), then $0 = 0$, and $z_v$ is determined by the $\\max_z$ optimization.\n",
    "\n",
    "### 3. Define Best- and Worst-Case Performance\n",
    "\n",
    "With a fixed budget $B$ (i.e., $\\sum_{v \\in I} y_v = B$), we can find the \"best\" and \"worst\" algorithm subclasses that \"nature\" can create:\n",
    "\n",
    "$$V_{\\text{best}}(B) = \\max_{y: \\sum y_v = B, \\zeta} Q(y, \\zeta)$$\n",
    "*(The highest possible reward. This is the optimistic case where \"nature\" chooses the $B$ variables $y$ and their values $\\zeta$ in the *least* harmful way.)*\n",
    "\n",
    "$$V_{\\text{worst}}(B) = \\min_{y: \\sum y_v = B, \\zeta} Q(y, \\zeta)$$\n",
    "*(The lowest possible reward. This is the pessimistic, worst-case scenario where \"nature\" chooses the $B$ variables $y$ and their values $\\zeta$ in the *most* harmful way.)*\n",
    "\n",
    "### 4. Analyze the Full Spectrum with Risk Parameter $\\alpha$\n",
    "\n",
    "For a given risk-tolerance $\\alpha \\in [0, 1]$, we want to find an algorithm (i.e., a set of fixed variables $y, \\zeta$) that achieves the best possible performance, *given* that this performance must be at least as good as the $\\alpha$-weighted threshold:\n",
    "\n",
    "$$\\max_{y, \\zeta} \\quad Q(y, \\zeta)$$\n",
    "$$\\text{s.t.} \\quad \\sum_{v \\in I} y_v = B$$\n",
    "$$Q(y, \\zeta) \\ge (1-\\alpha)V_{\\text{best}}(B) + \\alpha V_{\\text{worst}}(B)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fea63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building V_worst(1) bilevel MIP for n=100, K=2...\n",
      "Applying 'core.lp_dual' transformation...\n",
      "MIP built. Solving with Gurobi...\n",
      "Read LP format model from file /var/folders/z0/594mwlc93jv68hfyqzg2rzn40000gn/T/tmpev4177np.pyomo.lp\n",
      "Reading time = 0.04 seconds\n",
      "x1: 401 rows, 1996 columns, 60996 nonzeros\n",
      "Set parameter TimeLimit to value 300\n",
      "Set parameter MIPGap to value 0.01\n",
      "Set parameter MIPFocus to value 3\n",
      "Set parameter ScaleFlag to value 2\n",
      "Gurobi Optimizer version 12.0.3 build v12.0.3rc0 (mac64[rosetta2] - Darwin 24.6.0 24G90)\n",
      "\n",
      "CPU model: Apple M1\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  300\n",
      "MIPGap  0.01\n",
      "ScaleFlag  2\n",
      "MIPFocus  3\n",
      "\n",
      "Academic license 2418152 - for non-commercial use only - registered to ml___@rice.edu\n",
      "Optimize a model with 401 rows, 1996 columns and 60996 nonzeros\n",
      "Model fingerprint: 0xd4af64ab\n",
      "Model has 1600 quadratic objective terms\n",
      "Variable types: 1596 continuous, 400 integer (400 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-02, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  QObjective range [2e+00, 2e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e-04, 1e+00]\n",
      "Found heuristic solution: objective 8.1790000\n",
      "Presolve time: 0.05s\n",
      "Presolved: 3601 rows, 6796 columns, 68996 nonzeros\n",
      "Presolved model has 3200 SOS constraint(s)\n",
      "Variable types: 4396 continuous, 2400 integer (2400 binary)\n",
      "Root relaxation presolve removed 3201 rows and 4002 columns\n",
      "\n",
      "Root relaxation: unbounded, 0 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     2  postponed    0         8.17900          -      -     -    0s\n",
      "  1157  1962  postponed   50         8.17900          -      -  59.4    5s\n",
      "* 1969  1872              13       0.3646927          -      -  40.7    6s\n",
      "  3159  3163  postponed   30         0.36469          -      -  52.9   10s\n",
      "  5454  4276  postponed   72         0.36469          -      -  44.5   15s\n",
      "  7834  5641     cutoff  367         0.36469          -      -  38.2   20s\n",
      "  9541  7173     cutoff  541         0.36469          -      -  39.0   25s\n",
      " 12026  9015     cutoff  613         0.36469          -      -  37.3   30s\n",
      " 14007 10852  postponed  546         0.36469          -      -  35.8   35s\n",
      " 16198 12394  postponed  684         0.36469          -      -  33.9   41s\n",
      " 18004 13828  postponed  704         0.36469          -      -  32.4   45s\n",
      " 20850 15258     cutoff  719         0.36469          -      -  29.9   51s\n",
      " 23264 16783  postponed  800         0.36469          -      -  28.9   56s\n",
      " 25861 17492  postponed  720         0.36469          -      -  28.0   61s\n",
      " 28385 18290  postponed  794         0.36469          -      -  27.1   65s\n",
      " 30931 19028  postponed  778         0.36469          -      -  26.2   71s\n",
      " 33353 19608     cutoff  789         0.36469          -      -  25.5   75s\n",
      " 36654 20156  postponed  800         0.36469          -      -  24.8   81s\n",
      " 39098 20575  postponed  793         0.36469          -      -  24.3   86s\n",
      " 41547 21043  postponed  798         0.36469          -      -  23.9   90s\n",
      " 44023 21573     cutoff  797         0.36469          -      -  23.4   96s\n",
      " 46558 21930  postponed  804         0.36469          -      -  22.9  100s\n",
      " 49787 22303     cutoff  789         0.36469          -      -  22.5  106s\n",
      " 52226 22724     cutoff  809         0.36469          -      -  22.1  110s\n",
      " 54689 23035     cutoff  807         0.36469          -      -  21.9  115s\n",
      " 58016 23374  postponed  808         0.36469          -      -  21.4  120s\n",
      " 60593 23617     cutoff  801         0.36469          -      -  21.1  125s\n",
      " 63812 23886  postponed  807         0.36469          -      -  20.7  130s\n",
      " 66201 24161  postponed  804         0.36469          -      -  20.5  135s\n",
      "\n",
      "Interrupt request received\n",
      "\n",
      "Explored 68027 nodes (1382888 simplex iterations) in 137.15 seconds (108.65 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 0.364693 8.179 \n",
      "\n",
      "Solve interrupted\n",
      "Best objective 3.646926816422e-01, best bound -, gap -\n",
      "WARNING: Loading a SolverResults object with an 'aborted' status, but\n",
      "containing a solution\n",
      "MIP optimization failed with status error\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, [])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def solve_v_worst_bilevel(n, K, B):\n",
    "#     \"\"\"\n",
    "#     Solves the V_worst(B) bilevel problem using Pyomo and dualization.\n",
    "#     \"\"\"\n",
    "#     print(f\"\\nBuilding V_worst({B}) bilevel MIP for n={n}, K={K}...\")\n",
    "\n",
    "#     # Create the outer model\n",
    "#     m = pyo.ConcreteModel()\n",
    "#     M_val = 1.05\n",
    "\n",
    "#     # --- Indices (for outer vars) ---\n",
    "#     m.J = pyo.Set(initialize=range(K))\n",
    "#     m.K = pyo.Set(initialize=range(K))\n",
    "#     m.I = pyo.Set(initialize=range(n))\n",
    "#     m.VARS = m.J * m.K * m.I\n",
    "\n",
    "#     # --- Upper Level (Nature's) Variables ---\n",
    "#     m.y = pyo.Var(m.VARS, domain=pyo.Binary)\n",
    "#     m.zeta = pyo.Var(m.VARS, bounds=(0.0, 1.0))\n",
    "    \n",
    "#     # --- Upper Level (Nature's) Constraints ---\n",
    "#     m.budget = pyo.Constraint(expr=sum(m.y[v] for v in m.VARS) == B)\n",
    "\n",
    "#     # --- Inner Level (Primal) Problem ---\n",
    "#     # Get the base LP from our builder function\n",
    "#     m.primal_model = create_k_secretary_lp_model(n, K, verbose=False)\n",
    "    \n",
    "#     # --- Add Linking Constraints ---\n",
    "#     m.primal_model.linking_constrs_upper = pyo.Constraint(\n",
    "#         m.VARS,\n",
    "#         rule=lambda model, j, k, i: \n",
    "#             model.z[(j,k,i)] - m.zeta[(j,k,i)] <= M_val * (1.0 - m.y[(j,k,i)])\n",
    "#     )\n",
    "\n",
    "#     m.primal_model.linking_constrs_lower = pyo.Constraint(\n",
    "#         m.VARS, \n",
    "#         rule=lambda model, j, k, i: \n",
    "#             model.z[(j,k,i)] - m.zeta[(j,k,i)] >= -M_val * (1.0 - m.y[(j,k,i)])\n",
    "#     )\n",
    "\n",
    "#     # --- Apply Dual Transformation ---\n",
    "#     # This transforms the inner `m.primal_model` block into its dual\n",
    "#     # and parameterizes it with respect to the outer `m.y` variables.\n",
    "#     print(\"Applying 'core.lp_dual' transformation...\")\n",
    "#     dual_transformer = pyo.TransformationFactory('core.lp_dual')\n",
    "#     dualblk = dual_transformer.create_using(m.primal_model, parameterize_wrt=[m.y, m.zeta])\n",
    "#     m.add_component(\"worst_sensor_values_dual\", dualblk)\n",
    "\n",
    "#     # Deactivate the primal block, we now solve the MIP\n",
    "#     m.primal_model.deactivate()\n",
    "\n",
    "#     # --- Solve the Bilevel MIP ---\n",
    "#     print(\"MIP built. Solving with Gurobi...\")\n",
    "#     opt = SolverFactory('gurobi')\n",
    "#     opt.options['TimeLimit'] = 300\n",
    "#     opt.options['MIPGap'] = 0.01\n",
    "#     # opt.options['MIPFocus'] = 3\n",
    "#     # opt.options['ScaleFlag'] = 2\n",
    "#     results = opt.solve(m, tee=True)\n",
    "\n",
    "#     # --- Process Results ---\n",
    "#     v_worst = None\n",
    "#     worst_vars = []\n",
    "    \n",
    "#     if results.solver.termination_condition == pyo.TerminationCondition.optimal:\n",
    "#         v_worst = results.problem.lower_bound\n",
    "#         print(f\"\\n{'='*60}\\nSOLVE COMPLETE\\n{'='*60}\")\n",
    "#         print(f\"Solver Status: {results.solver.termination_condition}\")\n",
    "#         print(f\"V_worst({B}) = {v_worst:.6f}\")\n",
    "        \n",
    "#         print(f\"\\nWorst {B} variable(s) to fix to 0 (y_v = 1):\")\n",
    "#         for v in m.VARS:\n",
    "#             # Need to use .stale=True because we're checking var values\n",
    "#             # from a problem that was transformed.\n",
    "#             if pyo.value(m.y[v], exception=False) > 0.5:\n",
    "#                 worst_vars.append(v)\n",
    "#         print(worst_vars)\n",
    "        \n",
    "#     else:\n",
    "#         print(f\"MIP optimization failed with status {results.solver.termination_condition}\")\n",
    "\n",
    "#     return v_worst, worst_vars\n",
    "\n",
    "# solve_v_worst_bilevel(n_demo, K_demo, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0gmst0vvkvm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TESTING: Does restricting to meaningful vars change optimal value?\n",
      "============================================================\n",
      "\n",
      "Meaningful variables: 378 / 400\n",
      "\n",
      "Unrestricted LP objective: 0.987887\n",
      "Restricted LP objective:   0.987887\n",
      "Difference:                0.0000000000\n",
      "\n",
      "✓ PASS: Restriction does not change optimal value!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, let's verify that restricting to meaningful variables doesn't change the base LP\n",
    "# We'll solve the base LP with only meaningful variables and compare to original\n",
    "\n",
    "def test_meaningful_vars_restriction(n, K, coeff_threshold=1e-3):\n",
    "    \"\"\"\n",
    "    Test if restricting to meaningful variables changes the optimal objective.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TESTING: Does restricting to meaningful vars change optimal value?\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Compute meaningful variables\n",
    "    delta = np.zeros((n, K, K))\n",
    "    for i in range(1, n + 1):\n",
    "        for k in range(1, K + 1):\n",
    "            for ell in range(k, K + 1):\n",
    "                delta[i-1, k-1, ell-1] = compute_delta(n, i, k, ell)\n",
    "    \n",
    "    c_dict = {}\n",
    "    for j in range(K):\n",
    "        for k in range(K):\n",
    "            for i in range(n):\n",
    "                c_val = 0.0\n",
    "                for ell in range(k, K):\n",
    "                    c_val += (1.0 / n) * delta[i, k, ell]\n",
    "                c_dict[(j, k, i)] = c_val\n",
    "    \n",
    "    meaningful_vars = []\n",
    "    for j in range(K):\n",
    "        for k in range(K):\n",
    "            for i in range(n):\n",
    "                if i < k or i == 0:\n",
    "                    continue\n",
    "                if abs(c_dict[(j, k, i)]) > coeff_threshold:\n",
    "                    meaningful_vars.append((j, k, i))\n",
    "    \n",
    "    print(f\"Meaningful variables: {len(meaningful_vars)} / {K*K*n}\")\n",
    "    \n",
    "    # Solve base LP (unrestricted)\n",
    "    base_model, obj_unrestricted = solve_base_lp_pyomo(n, K, verbose=False)\n",
    "    print(f\"\\nUnrestricted LP objective: {obj_unrestricted:.6f}\")\n",
    "    \n",
    "    # Now solve with non-meaningful variables constrained to 0\n",
    "    model_restricted = create_k_secretary_lp_model(n, K, verbose=False)\n",
    "    \n",
    "    # Constrain non-meaningful vars to 0\n",
    "    for j in range(K):\n",
    "        for k in range(K):\n",
    "            for i in range(n):\n",
    "                if (j, k, i) not in meaningful_vars:\n",
    "                    model_restricted.z[(j, k, i)].fix(0.0)\n",
    "    \n",
    "    opt = SolverFactory('gurobi')\n",
    "    results = opt.solve(model_restricted, tee=False)\n",
    "    \n",
    "    if results.solver.termination_condition == pyo.TerminationCondition.optimal:\n",
    "        obj_restricted = pyo.value(model_restricted.objective)\n",
    "        print(f\"Restricted LP objective:   {obj_restricted:.6f}\")\n",
    "        print(f\"Difference:                {abs(obj_unrestricted - obj_restricted):.10f}\")\n",
    "        \n",
    "        if abs(obj_unrestricted - obj_restricted) < 1e-6:\n",
    "            print(f\"\\n✓ PASS: Restriction does not change optimal value!\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"\\n✗ FAIL: Restriction changes optimal value by {abs(obj_unrestricted - obj_restricted):.6f}\")\n",
    "            return False\n",
    "    else:\n",
    "        print(f\"Restricted LP failed to solve\")\n",
    "        return False\n",
    "\n",
    "# Run the test\n",
    "test_meaningful_vars_restriction(n_demo, K_demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wupviuu19ns",
   "metadata": {},
   "source": [
    "## Computing V_best and V_worst\n",
    "\n",
    "For a fixed budget $B$:\n",
    "- $V_{\\text{best}}(B) = V_{\\text{best}}(0)$ = optimal LP value (nature cannot improve beyond optimal)\n",
    "- $V_{\\text{worst}}(B)$ = minimum performance when nature fixes $B$ variables to 0\n",
    "\n",
    "We use **enumeration** to compute $V_{\\text{worst}}(B)$ exactly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "jkyayafs8lg",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Computing V_best and V_worst for B=1\n",
      "============================================================\n",
      "\n",
      "Solving V_worst(1) by enumeration...\n",
      "  Meaningful variables: 378\n",
      "  Combinations to try: 378\n",
      "  Progress: 300/378\n",
      "  V_worst(1) = 0.983489\n",
      "\n",
      "============================================================\n",
      "V_best(1)  = 0.987887  (competitive ratio: 0.493943)\n",
      "V_worst(1) = 0.983489  (competitive ratio: 0.491744)\n",
      "\n",
      "Worst-case configuration (variables fixed to 0):\n",
      "  z[1,0,42] = 0\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Helper function to identify meaningful variables\n",
    "def get_meaningful_vars(n, K, coeff_threshold=1e-3):\n",
    "    \"\"\"Identify variables with non-negligible objective coefficients.\"\"\"\n",
    "    delta = np.zeros((n, K, K))\n",
    "    for i in range(1, n + 1):\n",
    "        for k in range(1, K + 1):\n",
    "            for ell in range(k, K + 1):\n",
    "                delta[i-1, k-1, ell-1] = compute_delta(n, i, k, ell)\n",
    "    \n",
    "    c_dict = {}\n",
    "    for j in range(K):\n",
    "        for k in range(K):\n",
    "            for i in range(n):\n",
    "                c_val = 0.0\n",
    "                for ell in range(k, K):\n",
    "                    c_val += (1.0 / n) * delta[i, k, ell]\n",
    "                c_dict[(j, k, i)] = c_val\n",
    "    \n",
    "    meaningful_vars = []\n",
    "    for j in range(K):\n",
    "        for k in range(K):\n",
    "            for i in range(n):\n",
    "                if i < k or i == 0:\n",
    "                    continue\n",
    "                if abs(c_dict[(j, k, i)]) > coeff_threshold:\n",
    "                    meaningful_vars.append((j, k, i))\n",
    "    \n",
    "    return meaningful_vars, c_dict\n",
    "\n",
    "\n",
    "def create_k_secretary_lp_model_restricted(n, K, meaningful_vars, verbose=False):\n",
    "    \"\"\"Creates LP with only meaningful variables (non-meaningful implicitly 0).\"\"\"\n",
    "    delta = np.zeros((n, K, K))\n",
    "    for i in range(1, n + 1):\n",
    "        for k in range(1, K + 1):\n",
    "            for ell in range(k, K + 1):\n",
    "                delta[i-1, k-1, ell-1] = compute_delta(n, i, k, ell)\n",
    "    \n",
    "    model = pyo.ConcreteModel()\n",
    "    model.VARS = pyo.Set(initialize=meaningful_vars)\n",
    "    model.z = pyo.Var(model.VARS, bounds=(0.0, 1.0))\n",
    "\n",
    "    # Objective\n",
    "    c_dict = {}\n",
    "    for j, k, i in model.VARS:\n",
    "        c_val = 0.0\n",
    "        for ell in range(k, K):\n",
    "            c_val += (1.0 / n) * delta[i, k, ell]\n",
    "        c_dict[(j,k,i)] = c_val\n",
    "    \n",
    "    model.objective = pyo.Objective(\n",
    "        expr=sum(c_dict[v] * model.z[v] for v in model.VARS),\n",
    "        sense=pyo.maximize\n",
    "    )\n",
    "\n",
    "    # Constraints (only for meaningful variables)\n",
    "    model.lp_constrs = pyo.ConstraintList()\n",
    "\n",
    "    # Constraints for j < K\n",
    "    for j in range(K - 1):\n",
    "        for k in range(K):\n",
    "            for i in range(1, n):\n",
    "                if (j, k, i) not in meaningful_vars:\n",
    "                    continue\n",
    "                \n",
    "                rhs = 0\n",
    "                for m in range(i):\n",
    "                    for ell in range(K):\n",
    "                        if (j+1, ell, m) in meaningful_vars:\n",
    "                            rhs += (1.0 / (m + 1)) * model.z[(j+1, ell, m)]\n",
    "                        if (j, ell, m) in meaningful_vars:\n",
    "                            rhs -= (1.0 / (m + 1)) * model.z[(j, ell, m)]\n",
    "                \n",
    "                model.lp_constrs.add(model.z[(j, k, i)] <= rhs)\n",
    "    \n",
    "    # Constraints for j = K\n",
    "    j = K - 1\n",
    "    for k in range(K):\n",
    "        for i in range(1, n):\n",
    "            if (j, k, i) not in meaningful_vars:\n",
    "                continue\n",
    "            \n",
    "            rhs = 1.0\n",
    "            for m in range(i):\n",
    "                for ell in range(K):\n",
    "                    if (j, ell, m) in meaningful_vars:\n",
    "                        rhs -= (1.0 / (m + 1)) * model.z[(j, ell, m)]\n",
    "            \n",
    "            model.lp_constrs.add(model.z[(j, k, i)] <= rhs)\n",
    "        \n",
    "    return model\n",
    "\n",
    "\n",
    "def solve_v_worst_enumeration(n, K, B, coeff_threshold=1e-3):\n",
    "    \"\"\"\n",
    "    Solve V_worst(B) by enumerating all C(|meaningful_vars|, B) combinations.\n",
    "    Nature fixes B variables to 0 (the worst case).\n",
    "    \n",
    "    Returns the minimum objective value and which variables to fix to 0.\n",
    "    \"\"\"\n",
    "    meaningful_vars, c_dict = get_meaningful_vars(n, K, coeff_threshold)\n",
    "    \n",
    "    print(f\"Solving V_worst({B}) by enumeration...\")\n",
    "    print(f\"  Meaningful variables: {len(meaningful_vars)}\")\n",
    "    print(f\"  Combinations to try: {comb(len(meaningful_vars), B, exact=True)}\")\n",
    "    \n",
    "    from itertools import combinations\n",
    "    \n",
    "    v_worst = float('inf')\n",
    "    worst_vars = None\n",
    "    opt = SolverFactory('gurobi')\n",
    "    \n",
    "    # Try all combinations of B variables to fix to 0\n",
    "    for i, vars_to_fix in enumerate(combinations(meaningful_vars, B)):\n",
    "        if i % 100 == 0:\n",
    "            print(f\"  Progress: {i}/{comb(len(meaningful_vars), B, exact=True)}\", end='\\r')\n",
    "        \n",
    "        model = create_k_secretary_lp_model_restricted(n, K, meaningful_vars)\n",
    "        \n",
    "        # Fix selected variables to 0\n",
    "        for v in vars_to_fix:\n",
    "            model.z[v].fix(0.0)\n",
    "        \n",
    "        results = opt.solve(model, tee=False)\n",
    "        \n",
    "        if results.solver.termination_condition == pyo.TerminationCondition.optimal:\n",
    "            obj_val = pyo.value(model.objective)\n",
    "            if obj_val < v_worst:\n",
    "                v_worst = obj_val\n",
    "                worst_vars = vars_to_fix\n",
    "        \n",
    "        for v in vars_to_fix:\n",
    "            model.z[v].unfix()\n",
    "    \n",
    "    print(f\"\\n  V_worst({B}) = {v_worst:.6f}\")\n",
    "    \n",
    "    return v_worst, list(worst_vars) if worst_vars else []\n",
    "\n",
    "\n",
    "# Demo: Compute V_best and V_worst for B=1\n",
    "B_demo = 1\n",
    "print(f\"\\n{'='*60}\\nComputing V_best and V_worst for B={B_demo}\\n{'='*60}\\n\")\n",
    "\n",
    "v_best = obj_val_base  # Optimal LP value\n",
    "v_worst, worst_vars = solve_v_worst_enumeration(n_demo, K_demo, B_demo)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"V_best({B_demo})  = {v_best:.6f}  (competitive ratio: {v_best/K_demo:.6f})\")\n",
    "print(f\"V_worst({B_demo}) = {v_worst:.6f}  (competitive ratio: {v_worst/K_demo:.6f})\")\n",
    "if worst_vars:\n",
    "    print(f\"\\nWorst-case configuration (variables fixed to 0):\")\n",
    "    for v in worst_vars:\n",
    "        j, k, i = v\n",
    "        print(f\"  z[{j},{k},{i}] = 0\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rq9x6vmeuq",
   "metadata": {},
   "source": [
    "## Finding Algorithms with Risk Parameter $\\alpha$\n",
    "\n",
    "Given $\\alpha \\in [0,1]$, find the **best** algorithm subject to a performance guarantee:\n",
    "\n",
    "$$\\max_{y, \\zeta} Q(y, \\zeta)$$\n",
    "$$\\text{s.t.} \\quad \\sum_v y_v = B$$\n",
    "$$Q(y, \\zeta) \\leq (1-\\alpha) V_{\\text{best}}(B) + \\alpha V_{\\text{worst}}(B)$$\n",
    "\n",
    "where:\n",
    "- $\\alpha = 0$: Find best algorithm (may be risky)\n",
    "- $\\alpha = 1$: Find algorithm matching worst-case (most conservative)\n",
    "- $\\alpha \\in (0,1)$: Trade-off between performance and robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "svlgt140hke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Finding α-risk algorithms\n",
      "============================================================\n",
      "\n",
      "\n",
      "Finding α-risk algorithm with α=0.2, B=1...\n",
      "  Performance threshold: 0.987007\n",
      "  Enumerating over 378 combinations...\n",
      "  Progress: 300/378\n",
      "  Best performance found: 0.987887\n",
      "\n",
      "α=0.2: Performance = 0.987887\n",
      "    Fix z[1,0,44] = 0.500000\n",
      "\n",
      "\n",
      "Finding α-risk algorithm with α=0.5, B=1...\n",
      "  Performance threshold: 0.985688\n",
      "  Enumerating over 378 combinations...\n",
      "  Progress: 300/378\n",
      "  Best performance found: 0.987887\n",
      "\n",
      "α=0.5: Performance = 0.987887\n",
      "    Fix z[1,0,44] = 0.500000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def solve_alpha_risk_algorithm(n, K, B, alpha, v_best, v_worst, coeff_threshold=1e-3):\n",
    "    \"\"\"\n",
    "    Find algorithm (y, zeta) that maximizes performance subject to:\n",
    "        Q(y, zeta) >= (1-alpha)*v_best + alpha*v_worst\n",
    "    \n",
    "    Uses enumeration over y (which vars to fix) and optimization over zeta (what values).\n",
    "    \n",
    "    Args:\n",
    "        alpha: Risk parameter in [0,1]. 0=best, 1=worst-case\n",
    "        v_best: V_best(B) value\n",
    "        v_worst: V_worst(B) value\n",
    "    \n",
    "    Returns:\n",
    "        (performance, vars_to_fix, fixed_values)\n",
    "    \"\"\"\n",
    "    meaningful_vars, c_dict = get_meaningful_vars(n, K, coeff_threshold)\n",
    "    \n",
    "    threshold = (1 - alpha) * v_best + alpha * v_worst\n",
    "    \n",
    "    print(f\"\\nFinding α-risk algorithm with α={alpha}, B={B}...\")\n",
    "    print(f\"  Performance threshold: {threshold:.6f}\")\n",
    "    print(f\"  Enumerating over {comb(len(meaningful_vars), B, exact=True)} combinations...\")\n",
    "    \n",
    "    from itertools import combinations\n",
    "    \n",
    "    best_performance = -float('inf')\n",
    "    best_config = None\n",
    "    opt = SolverFactory('gurobi')\n",
    "    \n",
    "    # For each choice of which B variables to fix\n",
    "    for i, vars_to_fix in enumerate(combinations(meaningful_vars, B)):\n",
    "        if i % 100 == 0:\n",
    "            print(f\"  Progress: {i}/{comb(len(meaningful_vars), B, exact=True)}\", end='\\r')\n",
    "        \n",
    "        # For each choice of what values to fix them to\n",
    "        # Since we're maximizing, we want to set them to maximize objective\n",
    "        # subject to threshold constraint\n",
    "        \n",
    "        # Try setting to their \"optimal\" values (from unconstrained LP)\n",
    "        model_unconstrained = create_k_secretary_lp_model_restricted(n, K, meaningful_vars)\n",
    "        results = opt.solve(model_unconstrained, tee=False)\n",
    "        \n",
    "        if results.solver.termination_condition != pyo.TerminationCondition.optimal:\n",
    "            continue\n",
    "        \n",
    "        # Get optimal z values for the variables we want to fix\n",
    "        zeta_vals = {v: pyo.value(model_unconstrained.z[v]) for v in vars_to_fix}\n",
    "        \n",
    "        # Now solve LP with these variables fixed to zeta_vals\n",
    "        model_fixed = create_k_secretary_lp_model_restricted(n, K, meaningful_vars)\n",
    "        for v in vars_to_fix:\n",
    "            model_fixed.z[v].fix(zeta_vals[v])\n",
    "        \n",
    "        results_fixed = opt.solve(model_fixed, tee=False)\n",
    "        \n",
    "        if results_fixed.solver.termination_condition == pyo.TerminationCondition.optimal:\n",
    "            performance = pyo.value(model_fixed.objective)\n",
    "            \n",
    "            # Check if meets threshold and improves best\n",
    "            if performance >= threshold and performance > best_performance:\n",
    "                best_performance = performance\n",
    "                best_config = (vars_to_fix, zeta_vals)\n",
    "    \n",
    "    print(f\"\\n  Best performance found: {best_performance:.6f}\")\n",
    "    \n",
    "    if best_config:\n",
    "        vars_to_fix, zeta_vals = best_config\n",
    "        return best_performance, list(vars_to_fix), zeta_vals\n",
    "    else:\n",
    "        print(\"  No configuration meets the threshold!\")\n",
    "        return None, None, None\n",
    "\n",
    "\n",
    "# Demo: Find algorithms for different risk levels\n",
    "print(f\"\\n{'='*60}\\nFinding α-risk algorithms\\n{'='*60}\\n\")\n",
    "\n",
    "for alpha in [0.2, 0.5]:\n",
    "    perf, vars_fixed, zeta_vals = solve_alpha_risk_algorithm(\n",
    "        n_demo, K_demo, B_demo, alpha, v_best, v_worst\n",
    "    )\n",
    "    \n",
    "    if perf is not None:\n",
    "        print(f\"\\nα={alpha}: Performance = {perf:.6f}\")\n",
    "        if vars_fixed:\n",
    "            for v in vars_fixed:\n",
    "                j, k, i = v\n",
    "                print(f\"    Fix z[{j},{k},{i}] = {zeta_vals[v]:.6f}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
